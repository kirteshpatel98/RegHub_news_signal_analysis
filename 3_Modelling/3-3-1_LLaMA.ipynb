{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b0e2cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\scipy\\__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.20.0)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "# ! pip install transformers\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchsummary as summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import base64\n",
    "import gc\n",
    "import glob, os\n",
    "\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from reghub_pack.general_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4747ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "# Access aws credentials from json file\n",
    "with open(\"../aws_credentials.json\", 'r') as file:\n",
    "    aws_creds_json = json.load(file)\n",
    "# Specify s3 bucket\n",
    "bucket = \"fs-reghub-news-analysis\"\n",
    "\n",
    "# Connect to aws and dowload the files\n",
    "aws = awsOps(aws_creds_json)\n",
    "df = aws.get_df(bucket=bucket, file=\"data_rule_labels_v1.csv\")\n",
    "df_categories = aws.get_df(bucket=bucket, file=\"rule_labels_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c167f8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Berenberg Bank analysts have provided a buy ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The article states that Berenberg, a German in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In their analysis on October 30, 2023, experts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Berenberg Bank has issued a \\\"buy\\\" recommenda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The private bank Berenberg has upgraded its ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14496</th>\n",
       "      <td>INTERVIEW Interview with Les Échos Interview w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14497</th>\n",
       "      <td>UBS's latest Investor Watch report reveals tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14498</th>\n",
       "      <td>SNB erwartet für 2021 Jahresgewinn von rund 26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14499</th>\n",
       "      <td>0:00 News A cryptocurrency exchange in Hong Ko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14500</th>\n",
       "      <td>Bloomberg has reported that a number of indivi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14501 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            news_content\n",
       "0      Berenberg Bank analysts have provided a buy ra...\n",
       "1      The article states that Berenberg, a German in...\n",
       "2      In their analysis on October 30, 2023, experts...\n",
       "3      Berenberg Bank has issued a \\\"buy\\\" recommenda...\n",
       "4      The private bank Berenberg has upgraded its ra...\n",
       "...                                                  ...\n",
       "14496  INTERVIEW Interview with Les Échos Interview w...\n",
       "14497  UBS's latest Investor Watch report reveals tha...\n",
       "14498  SNB erwartet für 2021 Jahresgewinn von rund 26...\n",
       "14499  0:00 News A cryptocurrency exchange in Hong Ko...\n",
       "14500  Bloomberg has reported that a number of indivi...\n",
       "\n",
       "[14501 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "df=df[['news_content','rule_labels_comb']]\n",
    "df = df.reset_index()\n",
    "del df['index'], df['rule_labels_comb']\n",
    "# df['target'] = df['news_content']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8167548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test= train_test_split(df[['news_content','target']], test_size=0.25)\n",
    "X_train, X_test= train_test_split(df[['news_content']], test_size=0.25)\n",
    "\n",
    "df_train=X_train\n",
    "df_val=X_test\n",
    "df_test=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ef5293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.reset_index()\n",
    "df_train.drop('index',axis=1,inplace=True)\n",
    "\n",
    "df_val=df_val.reset_index()\n",
    "df_val.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dbbd0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change datatypes of input data\n",
    "df_train['news_content']=df_train['news_content'].astype(str)\n",
    "\n",
    "df_val['news_content']=df_val['news_content'].astype(str)\n",
    "df_train['news_content'].iloc[0]\n",
    "train_data=df_train\n",
    "val_data=df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78a12646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "binary_path: C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll\n",
      "CUDA SETUP: Loading binary C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\bitsandbytes\\cuda_setup\\libbitsandbytes_cuda116.dll...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc416adc4224e929f608cdff900e0fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "# Add the parent directory to the Python path\n",
    "from reghub_pack.models import LLaMA_RegHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a01994c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e4aa282d0d49ca85d8d5b457129a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu and disk.\n"
     ]
    }
   ],
   "source": [
    "model=LLaMA_RegHub()\n",
    "# model.display_model_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0977d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "259cbc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.display_model_layers()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42eaeaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Epoch 1/100:   0%|                                                                           | 0/340 [00:00<?, ?item/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    1,   422,  1050, 29920,  9157,   756,  9326,   393,   967,  7613],\n",
      "       device='cuda:0')\n",
      "tensor([    1,   422,  1050, 29920,  9157,   756,  9326,   393,   967,  7613],\n",
      "       device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   0%|                                                                           | 0/340 [00:01<?, ?item/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_3676\\3004462831.py\", line 1, in <module>\n",
      "    model.model_training(train_data=train_data, val_data=val_data)\n",
      "  File \"C:\\Users\\hp\\OneDrive - fs-students.de\\FS\\Sem 3\\CCP\\RegHub_news_signal_analysis\\3_Modelling\\..\\reghub_pack\\models\\LLaMA.py\", line 195, in model_training\n",
      "    output = self(input_ids,labels)\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\hp\\OneDrive - fs-students.de\\FS\\Sem 3\\CCP\\RegHub_news_signal_analysis\\3_Modelling\\..\\reghub_pack\\models\\LLaMA.py\", line 62, in forward\n",
      "    output = self.llama(input_ids= input_ids, attention_mask=attention_mask,return_dict=False)\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\accelerate\\hooks.py\", line 165, in new_forward\n",
      "    output = module._old_forward(*args, **kwargs)\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py\", line 820, in forward\n",
      "    outputs = self.model(\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py\", line 708, in forward\n",
      "    layer_outputs = decoder_layer(\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\accelerate\\hooks.py\", line 165, in new_forward\n",
      "    output = module._old_forward(*args, **kwargs)\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py\", line 437, in forward\n",
      "    hidden_states = self.mlp(hidden_states)\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\accelerate\\hooks.py\", line 165, in new_forward\n",
      "    output = module._old_forward(*args, **kwargs)\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py\", line 220, in forward\n",
      "    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\accelerate\\hooks.py\", line 160, in new_forward\n",
      "    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\accelerate\\hooks.py\", line 293, in pre_forward\n",
      "    set_module_tensor_to_device(\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\accelerate\\utils\\modeling.py\", line 317, in set_module_tensor_to_device\n",
      "    new_value = value.to(device)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 6.00 GiB total capacity; 4.78 GiB already allocated; 182.00 MiB free; 4.81 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\executing\\executing.py\", line 317, in executing\n",
      "    args = executing_cache[key]\n",
      "KeyError: (<code object _call_impl at 0x00000183ACC3A240, file \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1494>, 1665050845760, 70)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1160, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\stack_data\\core.py\", line 565, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\stack_data\\utils.py\", line 84, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\stack_data\\core.py\", line 555, in mapper\n",
      "    return cls(f, options)\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\stack_data\\core.py\", line 520, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\executing\\executing.py\", line 369, in executing\n",
      "    args = find(source=cls.for_frame(frame), retry_cache=True)\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\executing\\executing.py\", line 252, in for_frame\n",
      "    return cls.for_filename(frame.f_code.co_filename, frame.f_globals or {}, use_cache)\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\executing\\executing.py\", line 270, in for_filename\n",
      "    result = source_cache[filename] = cls._for_filename_and_lines(filename, lines)\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\executing\\executing.py\", line 281, in _for_filename_and_lines\n",
      "    result = source_cache[(filename, lines)] = cls(filename, lines)\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\stack_data\\core.py\", line 81, in __init__\n",
      "    self.asttokens()\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\executing\\executing.py\", line 413, in asttokens\n",
      "    return ASTTokens(\n",
      "  File \"C:\\Users\\hp\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\asttokens\\asttokens.py\", line 59, in __init__\n",
      "    self._tokens = list(self._generate_tokens(source_text))\n",
      "MemoryError\n"
     ]
    }
   ],
   "source": [
    "model.model_training(train_data=train_data, val_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8295a0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e238069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([[[    1,   450,  4274 ]], [[    1,  1640,   422]],[[    1,  9788, 29892]]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba15ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc6e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:, :-1].contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7378aac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu1",
   "language": "python",
   "name": "gpu1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
