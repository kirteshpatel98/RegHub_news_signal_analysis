{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5d3343f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8648addd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom transformers import BertModel\\nmodel = BertModel.from_pretrained(\"bert-base-uncased\")\\n'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from transformers import BertModel\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e2184f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('BERT_comparison.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5a67d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "inputs = tokenizer(\"\"\" Commerzbank is working with Microsoft to use generative AI and avatar technology for a new virtual assistant in its mobile app.\n",
    "\n",
    "The avatar will be powered by Microsoft Azure OpenAI Service for advanced GPT models, enabling it to interact with the German lender's private and small business customers in \"natural and engaging conversations\".\n",
    "\n",
    "Customers can ask their virtual assistant questions and get general information as well as personalised advice.\n",
    "\n",
    "Jörg Oliveri del Castillo-Schulz, COO, Commerzbank, says: The launch of the Avatar project is a new chapter in Commerzbank’s digital strategy and a flagship use-case for Generative AI and Microsoft’s new cutting-edge Avatar technology. It will significantly improve the customer interface, customer experience and banking processes.\"\"\", return_tensors=\"pt\",padding='max_length',truncation=True)\n",
    "outputs = model(**inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "131e2939",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "inputs = tokenizer(\"\"\" Commerzbank is collaborating with Microsoft to integrate generative AI and avatar technology into its mobile application, creating a novel virtual assistant. This assistant will utilize Microsoft Azure's OpenAI Service, which includes advanced GPT models, allowing it to engage in fluid, captivating dialogues with the bank's individual and small business clients.\n",
    "\n",
    "Through this virtual assistant, users can pose questions and receive both general and tailored advice. Jörg Oliveri del Castillo-Schulz, COO of Commerzbank, remarks that the inception of the Avatar project marks a significant development in the bank's digital approach. He highlights it as a prime example of utilizing Generative AI and Microsoft's pioneering Avatar technology, noting its potential to markedly enhance customer interaction, user experience, and the efficiency of banking operations.\"\"\", return_tensors=\"pt\",padding='max_length',truncation=True)\n",
    "outputs1 = model(**inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6889760c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom transformers import AutoTokenizer\\nimport torch\\n\\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\\n\\ninputs = tokenizer(\"\"\" German lender Commerzbank saw its net profit after tax triple compared to last year thanks to its strategic roadmap.\\n\\nCommerzbank, the prominent German financial institution, reported impressive results for the third quarter of 2023 with a net profit after tax that reached €684 million.\\n\\nIt more than tripled compared to last year’s amount of €195 million.\\n\\nThe lender’s Q3 revenue meanwhile soared to €2.8 billion compared to €1.9 billion in 2022. Commerzbank attributed these results to robust customer business and continued benefits from interest rates.\\n\\n\"With our refined strategy, we are strengthening our position as a decisive player in the German banking market,” said Manfred Knof, Commerzbank’s CEO, in a statement, highlighting their efforts to increase revenue base, improve the cost-income ratio and boost profitability.\\n\\nThe bank will need to align with the evolving financial landscape and is planning to do so by focusing on digital banking solutions and opportunities in sustainable finance.\\n\\n“With ‘Strategy 2024’ we have successfully implemented difficult but necessary restructuring measures,” Knof added. “We have established a new business model and brought Commerzbank back on track for success.”\\n\\nThe restructuring measures involve closing 340 branches and cutting 10,000 jobs by 2024. €3.4 billion profits in the 2027 crosshairs\\n\\nThe bank aspires to increase net profit to €3.4 billion by 2027 and expects the return on tangible equity - a financial metric that measures a company\\'s profitability - to surpass 11%.\\n\\nCommerzbank plans to return more capital to its shareholders with a pay-out ratio well above 50% for 2025 to 2027, according to its statement.\\n\\nCommerzbank is the most popular bank among Germany’s Mittelstand (mid-sized companies) and operates in more than 40 countries. It has a strong presence in Europe and is growing its business in Asia and the Americas.\"\"\", return_tensors=\"pt\",padding=\\'max_length\\',truncation=True)\\noutputs1 = model(**inputs)\\n\\n'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "inputs = tokenizer(\"\"\" German lender Commerzbank saw its net profit after tax triple compared to last year thanks to its strategic roadmap.\n",
    "\n",
    "Commerzbank, the prominent German financial institution, reported impressive results for the third quarter of 2023 with a net profit after tax that reached €684 million.\n",
    "\n",
    "It more than tripled compared to last year’s amount of €195 million.\n",
    "\n",
    "The lender’s Q3 revenue meanwhile soared to €2.8 billion compared to €1.9 billion in 2022. Commerzbank attributed these results to robust customer business and continued benefits from interest rates.\n",
    "\n",
    "\"With our refined strategy, we are strengthening our position as a decisive player in the German banking market,” said Manfred Knof, Commerzbank’s CEO, in a statement, highlighting their efforts to increase revenue base, improve the cost-income ratio and boost profitability.\n",
    "\n",
    "The bank will need to align with the evolving financial landscape and is planning to do so by focusing on digital banking solutions and opportunities in sustainable finance.\n",
    "\n",
    "“With ‘Strategy 2024’ we have successfully implemented difficult but necessary restructuring measures,” Knof added. “We have established a new business model and brought Commerzbank back on track for success.”\n",
    "\n",
    "The restructuring measures involve closing 340 branches and cutting 10,000 jobs by 2024. €3.4 billion profits in the 2027 crosshairs\n",
    "\n",
    "The bank aspires to increase net profit to €3.4 billion by 2027 and expects the return on tangible equity - a financial metric that measures a company's profitability - to surpass 11%.\n",
    "\n",
    "Commerzbank plans to return more capital to its shareholders with a pay-out ratio well above 50% for 2025 to 2027, according to its statement.\n",
    "\n",
    "Commerzbank is the most popular bank among Germany’s Mittelstand (mid-sized companies) and operates in more than 40 countries. It has a strong presence in Europe and is growing its business in Asia and the Americas.\"\"\", return_tensors=\"pt\",padding='max_length',truncation=True)\n",
    "outputs1 = model(**inputs)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "75f30c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def cosine_similarity(tensor_a, tensor_b):\n",
    "    # Normalize tensor_a\n",
    "    norm_a = torch.norm(tensor_a)\n",
    "    normalized_a = tensor_a / norm_a\n",
    "\n",
    "    # Normalize tensor_b\n",
    "    norm_b = torch.norm(tensor_b)\n",
    "    normalized_b = tensor_b / norm_b\n",
    "\n",
    "    # Calculate dot product\n",
    "    cos_similarity = torch.dot(normalized_a.flatten(), normalized_b.flatten())\n",
    "\n",
    "    return cos_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3dac342c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7754, grad_fn=<DotBackward0>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(outputs[0].squeeze(),outputs1[0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "19ba4095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 768])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1[0].squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1c33ff4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0329, -0.1879,  0.0304,  ..., -0.5796,  0.3683, -0.3711],\n",
       "         [ 0.5576, -1.1683,  0.0883,  ...,  0.0933,  1.0286,  0.5280],\n",
       "         [ 0.4215, -1.3066,  1.2749,  ..., -0.1850,  0.7487, -0.2387],\n",
       "         ...,\n",
       "         [ 0.0577, -0.1203,  0.0878,  ..., -0.5892,  0.2989, -0.5728],\n",
       "         [ 0.0577, -0.1199,  0.0874,  ..., -0.5894,  0.2996, -0.5722],\n",
       "         [ 0.0577, -0.1203,  0.0869,  ..., -0.5893,  0.2993, -0.5729]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a5cc4e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight\n",
      "embeddings.position_embeddings.weight\n",
      "embeddings.token_type_embeddings.weight\n",
      "embeddings.LayerNorm.weight\n",
      "embeddings.LayerNorm.bias\n",
      "encoder.layer.0.attention.self.query.weight\n",
      "encoder.layer.0.attention.self.query.bias\n",
      "encoder.layer.0.attention.self.key.weight\n",
      "encoder.layer.0.attention.self.key.bias\n",
      "encoder.layer.0.attention.self.value.weight\n",
      "encoder.layer.0.attention.self.value.bias\n",
      "encoder.layer.0.attention.output.dense.weight\n",
      "encoder.layer.0.attention.output.dense.bias\n",
      "encoder.layer.0.attention.output.LayerNorm.weight\n",
      "encoder.layer.0.attention.output.LayerNorm.bias\n",
      "encoder.layer.0.intermediate.dense.weight\n",
      "encoder.layer.0.intermediate.dense.bias\n",
      "encoder.layer.0.output.dense.weight\n",
      "encoder.layer.0.output.dense.bias\n",
      "encoder.layer.0.output.LayerNorm.weight\n",
      "encoder.layer.0.output.LayerNorm.bias\n",
      "encoder.layer.1.attention.self.query.weight\n",
      "encoder.layer.1.attention.self.query.bias\n",
      "encoder.layer.1.attention.self.key.weight\n",
      "encoder.layer.1.attention.self.key.bias\n",
      "encoder.layer.1.attention.self.value.weight\n",
      "encoder.layer.1.attention.self.value.bias\n",
      "encoder.layer.1.attention.output.dense.weight\n",
      "encoder.layer.1.attention.output.dense.bias\n",
      "encoder.layer.1.attention.output.LayerNorm.weight\n",
      "encoder.layer.1.attention.output.LayerNorm.bias\n",
      "encoder.layer.1.intermediate.dense.weight\n",
      "encoder.layer.1.intermediate.dense.bias\n",
      "encoder.layer.1.output.dense.weight\n",
      "encoder.layer.1.output.dense.bias\n",
      "encoder.layer.1.output.LayerNorm.weight\n",
      "encoder.layer.1.output.LayerNorm.bias\n",
      "encoder.layer.2.attention.self.query.weight\n",
      "encoder.layer.2.attention.self.query.bias\n",
      "encoder.layer.2.attention.self.key.weight\n",
      "encoder.layer.2.attention.self.key.bias\n",
      "encoder.layer.2.attention.self.value.weight\n",
      "encoder.layer.2.attention.self.value.bias\n",
      "encoder.layer.2.attention.output.dense.weight\n",
      "encoder.layer.2.attention.output.dense.bias\n",
      "encoder.layer.2.attention.output.LayerNorm.weight\n",
      "encoder.layer.2.attention.output.LayerNorm.bias\n",
      "encoder.layer.2.intermediate.dense.weight\n",
      "encoder.layer.2.intermediate.dense.bias\n",
      "encoder.layer.2.output.dense.weight\n",
      "encoder.layer.2.output.dense.bias\n",
      "encoder.layer.2.output.LayerNorm.weight\n",
      "encoder.layer.2.output.LayerNorm.bias\n",
      "encoder.layer.3.attention.self.query.weight\n",
      "encoder.layer.3.attention.self.query.bias\n",
      "encoder.layer.3.attention.self.key.weight\n",
      "encoder.layer.3.attention.self.key.bias\n",
      "encoder.layer.3.attention.self.value.weight\n",
      "encoder.layer.3.attention.self.value.bias\n",
      "encoder.layer.3.attention.output.dense.weight\n",
      "encoder.layer.3.attention.output.dense.bias\n",
      "encoder.layer.3.attention.output.LayerNorm.weight\n",
      "encoder.layer.3.attention.output.LayerNorm.bias\n",
      "encoder.layer.3.intermediate.dense.weight\n",
      "encoder.layer.3.intermediate.dense.bias\n",
      "encoder.layer.3.output.dense.weight\n",
      "encoder.layer.3.output.dense.bias\n",
      "encoder.layer.3.output.LayerNorm.weight\n",
      "encoder.layer.3.output.LayerNorm.bias\n",
      "encoder.layer.4.attention.self.query.weight\n",
      "encoder.layer.4.attention.self.query.bias\n",
      "encoder.layer.4.attention.self.key.weight\n",
      "encoder.layer.4.attention.self.key.bias\n",
      "encoder.layer.4.attention.self.value.weight\n",
      "encoder.layer.4.attention.self.value.bias\n",
      "encoder.layer.4.attention.output.dense.weight\n",
      "encoder.layer.4.attention.output.dense.bias\n",
      "encoder.layer.4.attention.output.LayerNorm.weight\n",
      "encoder.layer.4.attention.output.LayerNorm.bias\n",
      "encoder.layer.4.intermediate.dense.weight\n",
      "encoder.layer.4.intermediate.dense.bias\n",
      "encoder.layer.4.output.dense.weight\n",
      "encoder.layer.4.output.dense.bias\n",
      "encoder.layer.4.output.LayerNorm.weight\n",
      "encoder.layer.4.output.LayerNorm.bias\n",
      "encoder.layer.5.attention.self.query.weight\n",
      "encoder.layer.5.attention.self.query.bias\n",
      "encoder.layer.5.attention.self.key.weight\n",
      "encoder.layer.5.attention.self.key.bias\n",
      "encoder.layer.5.attention.self.value.weight\n",
      "encoder.layer.5.attention.self.value.bias\n",
      "encoder.layer.5.attention.output.dense.weight\n",
      "encoder.layer.5.attention.output.dense.bias\n",
      "encoder.layer.5.attention.output.LayerNorm.weight\n",
      "encoder.layer.5.attention.output.LayerNorm.bias\n",
      "encoder.layer.5.intermediate.dense.weight\n",
      "encoder.layer.5.intermediate.dense.bias\n",
      "encoder.layer.5.output.dense.weight\n",
      "encoder.layer.5.output.dense.bias\n",
      "encoder.layer.5.output.LayerNorm.weight\n",
      "encoder.layer.5.output.LayerNorm.bias\n",
      "encoder.layer.6.attention.self.query.weight\n",
      "encoder.layer.6.attention.self.query.bias\n",
      "encoder.layer.6.attention.self.key.weight\n",
      "encoder.layer.6.attention.self.key.bias\n",
      "encoder.layer.6.attention.self.value.weight\n",
      "encoder.layer.6.attention.self.value.bias\n",
      "encoder.layer.6.attention.output.dense.weight\n",
      "encoder.layer.6.attention.output.dense.bias\n",
      "encoder.layer.6.attention.output.LayerNorm.weight\n",
      "encoder.layer.6.attention.output.LayerNorm.bias\n",
      "encoder.layer.6.intermediate.dense.weight\n",
      "encoder.layer.6.intermediate.dense.bias\n",
      "encoder.layer.6.output.dense.weight\n",
      "encoder.layer.6.output.dense.bias\n",
      "encoder.layer.6.output.LayerNorm.weight\n",
      "encoder.layer.6.output.LayerNorm.bias\n",
      "encoder.layer.7.attention.self.query.weight\n",
      "encoder.layer.7.attention.self.query.bias\n",
      "encoder.layer.7.attention.self.key.weight\n",
      "encoder.layer.7.attention.self.key.bias\n",
      "encoder.layer.7.attention.self.value.weight\n",
      "encoder.layer.7.attention.self.value.bias\n",
      "encoder.layer.7.attention.output.dense.weight\n",
      "encoder.layer.7.attention.output.dense.bias\n",
      "encoder.layer.7.attention.output.LayerNorm.weight\n",
      "encoder.layer.7.attention.output.LayerNorm.bias\n",
      "encoder.layer.7.intermediate.dense.weight\n",
      "encoder.layer.7.intermediate.dense.bias\n",
      "encoder.layer.7.output.dense.weight\n",
      "encoder.layer.7.output.dense.bias\n",
      "encoder.layer.7.output.LayerNorm.weight\n",
      "encoder.layer.7.output.LayerNorm.bias\n",
      "encoder.layer.8.attention.self.query.weight\n",
      "encoder.layer.8.attention.self.query.bias\n",
      "encoder.layer.8.attention.self.key.weight\n",
      "encoder.layer.8.attention.self.key.bias\n",
      "encoder.layer.8.attention.self.value.weight\n",
      "encoder.layer.8.attention.self.value.bias\n",
      "encoder.layer.8.attention.output.dense.weight\n",
      "encoder.layer.8.attention.output.dense.bias\n",
      "encoder.layer.8.attention.output.LayerNorm.weight\n",
      "encoder.layer.8.attention.output.LayerNorm.bias\n",
      "encoder.layer.8.intermediate.dense.weight\n",
      "encoder.layer.8.intermediate.dense.bias\n",
      "encoder.layer.8.output.dense.weight\n",
      "encoder.layer.8.output.dense.bias\n",
      "encoder.layer.8.output.LayerNorm.weight\n",
      "encoder.layer.8.output.LayerNorm.bias\n",
      "encoder.layer.9.attention.self.query.weight\n",
      "encoder.layer.9.attention.self.query.bias\n",
      "encoder.layer.9.attention.self.key.weight\n",
      "encoder.layer.9.attention.self.key.bias\n",
      "encoder.layer.9.attention.self.value.weight\n",
      "encoder.layer.9.attention.self.value.bias\n",
      "encoder.layer.9.attention.output.dense.weight\n",
      "encoder.layer.9.attention.output.dense.bias\n",
      "encoder.layer.9.attention.output.LayerNorm.weight\n",
      "encoder.layer.9.attention.output.LayerNorm.bias\n",
      "encoder.layer.9.intermediate.dense.weight\n",
      "encoder.layer.9.intermediate.dense.bias\n",
      "encoder.layer.9.output.dense.weight\n",
      "encoder.layer.9.output.dense.bias\n",
      "encoder.layer.9.output.LayerNorm.weight\n",
      "encoder.layer.9.output.LayerNorm.bias\n",
      "encoder.layer.10.attention.self.query.weight\n",
      "encoder.layer.10.attention.self.query.bias\n",
      "encoder.layer.10.attention.self.key.weight\n",
      "encoder.layer.10.attention.self.key.bias\n",
      "encoder.layer.10.attention.self.value.weight\n",
      "encoder.layer.10.attention.self.value.bias\n",
      "encoder.layer.10.attention.output.dense.weight\n",
      "encoder.layer.10.attention.output.dense.bias\n",
      "encoder.layer.10.attention.output.LayerNorm.weight\n",
      "encoder.layer.10.attention.output.LayerNorm.bias\n",
      "encoder.layer.10.intermediate.dense.weight\n",
      "encoder.layer.10.intermediate.dense.bias\n",
      "encoder.layer.10.output.dense.weight\n",
      "encoder.layer.10.output.dense.bias\n",
      "encoder.layer.10.output.LayerNorm.weight\n",
      "encoder.layer.10.output.LayerNorm.bias\n",
      "encoder.layer.11.attention.self.query.weight\n",
      "encoder.layer.11.attention.self.query.bias\n",
      "encoder.layer.11.attention.self.key.weight\n",
      "encoder.layer.11.attention.self.key.bias\n",
      "encoder.layer.11.attention.self.value.weight\n",
      "encoder.layer.11.attention.self.value.bias\n",
      "encoder.layer.11.attention.output.dense.weight\n",
      "encoder.layer.11.attention.output.dense.bias\n",
      "encoder.layer.11.attention.output.LayerNorm.weight\n",
      "encoder.layer.11.attention.output.LayerNorm.bias\n",
      "encoder.layer.11.intermediate.dense.weight\n",
      "encoder.layer.11.intermediate.dense.bias\n",
      "encoder.layer.11.output.dense.weight\n",
      "encoder.layer.11.output.dense.bias\n",
      "encoder.layer.11.output.LayerNorm.weight\n",
      "encoder.layer.11.output.LayerNorm.bias\n",
      "pooler.dense.weight\n",
      "pooler.dense.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display BERT layers\n",
    "n=0\n",
    "for x in model.state_dict():\n",
    "    n=n+1\n",
    "    print(x)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "456d1cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0329, -0.1879,  0.0304,  ..., -0.5796,  0.3683, -0.3711],\n",
       "         [ 0.5576, -1.1683,  0.0883,  ...,  0.0933,  1.0286,  0.5280],\n",
       "         [ 0.4215, -1.3066,  1.2749,  ..., -0.1850,  0.7487, -0.2387],\n",
       "         ...,\n",
       "         [ 0.0577, -0.1203,  0.0878,  ..., -0.5892,  0.2989, -0.5728],\n",
       "         [ 0.0577, -0.1199,  0.0874,  ..., -0.5894,  0.2996, -0.5722],\n",
       "         [ 0.0577, -0.1203,  0.0869,  ..., -0.5893,  0.2993, -0.5729]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.7251, -0.1188,  0.4982,  0.2730,  0.0015, -0.2003,  0.4017,  0.1176,\n",
       "          0.6309, -0.8471,  0.3682,  0.0821,  0.9276, -0.4579,  0.7953, -0.1578,\n",
       "         -0.0681, -0.1943,  0.2311, -0.3420,  0.5009,  0.1923,  0.4602,  0.2305,\n",
       "          0.3661, -0.2176, -0.1663,  0.8844,  0.8666,  0.6443, -0.2783,  0.2718,\n",
       "         -0.9512, -0.1520,  0.3082, -0.8737,  0.1554, -0.5835, -0.0083, -0.2728,\n",
       "         -0.8542,  0.1402,  0.7028, -0.1264,  0.0685, -0.2784, -0.9815,  0.2267,\n",
       "         -0.8330, -0.6314, -0.5431, -0.1017,  0.2185,  0.2853,  0.1807, -0.2783,\n",
       "          0.2726,  0.1590, -0.2564, -0.4789, -0.2581,  0.2444,  0.4789, -0.4842,\n",
       "         -0.7101, -0.7625, -0.2251, -0.1416, -0.3032,  0.1576,  0.2961,  0.2619,\n",
       "          0.1181, -0.5465, -0.6660,  0.1509,  0.3184,  0.9889, -0.3268, -0.9154,\n",
       "         -0.2127, -0.6936, -0.3918,  0.7865, -0.8001, -0.9848,  0.2002, -0.1342,\n",
       "         -0.9508,  0.2257,  0.0107, -0.2257, -0.6369, -0.4041,  0.5288, -0.1898,\n",
       "         -0.0801,  0.2628, -0.2658, -0.0749,  0.0503, -0.2401, -0.3363, -0.1530,\n",
       "          0.3000, -0.1910, -0.3540,  0.1726, -0.6295,  0.2802, -0.1772, -0.1394,\n",
       "          0.2235, -0.7819,  0.2929, -0.2940, -0.9466,  0.4270, -0.9658,  0.3560,\n",
       "          0.0108, -0.2634,  0.7900,  0.4939,  0.2303, -0.2406,  0.6581, -0.9907,\n",
       "          0.4130,  0.2061, -0.0990, -0.1202, -0.9413, -0.9118,  0.1790,  0.7579,\n",
       "          0.1209,  0.7276, -0.3194,  0.8741,  0.6326,  0.2441, -0.6550, -0.1236,\n",
       "         -0.2761,  0.1445, -0.2412,  0.0679, -0.1914, -0.1110, -0.1968, -0.2700,\n",
       "          0.6814, -0.5382, -0.2016,  0.8207,  0.2282,  0.7294,  0.7671, -0.4351,\n",
       "         -0.1545,  0.5856,  0.0850,  0.3118,  0.3091,  0.2701, -0.8389,  0.1491,\n",
       "         -0.5322,  0.3849,  0.3446, -0.1856,  0.4138, -0.8983, -0.3438,  0.4181,\n",
       "          0.9344,  0.6271,  0.2262, -0.3370, -0.3048, -0.2196, -0.9147,  0.9088,\n",
       "         -0.2199,  0.2536,  0.4623,  0.2298, -0.6723, -0.4586,  0.2994,  0.3401,\n",
       "         -0.7963, -0.3084, -0.1484, -0.2867,  0.0011,  0.4060, -0.2078, -0.2860,\n",
       "         -0.2444,  0.8172,  0.5823,  0.6261, -0.4306,  0.1740, -0.7925, -0.0961,\n",
       "          0.2785,  0.2319,  0.2545,  0.9309,  0.3141, -0.1011, -0.6065, -0.9177,\n",
       "          0.1578, -0.6535, -0.1649, -0.1610,  0.3857,  0.2334, -0.7173,  0.0850,\n",
       "         -0.7608, -0.3967,  0.2634, -0.1198,  0.2412, -0.3456, -0.0823, -0.2757,\n",
       "         -0.2079,  0.1391,  0.7016,  0.3153, -0.6996,  0.3973, -0.2552,  0.2962,\n",
       "         -0.1691,  0.6994, -0.4158,  0.2559, -0.9120,  0.6618, -0.5451,  0.7134,\n",
       "         -0.0461, -0.8738, -0.8169, -0.3644,  0.2599,  0.8682, -0.1069,  0.8698,\n",
       "          0.6468, -0.9180,  0.6149,  0.2681, -0.9340, -0.1461,  0.1224, -0.3800,\n",
       "         -0.2510, -0.2496, -0.9059,  0.2738,  0.2544,  0.7423,  0.0351, -0.3032,\n",
       "          0.1021, -0.8986,  0.2417, -0.2580,  0.7651,  0.3383, -0.7835,  0.2720,\n",
       "          0.5308,  0.3206,  0.6655,  0.8763,  0.6339,  0.8663,  0.7950,  0.5554,\n",
       "         -0.1518, -0.0096,  0.7362, -0.1895, -0.9112, -0.8136,  0.2000,  0.4193,\n",
       "         -0.9861, -0.0765, -0.2152, -0.8495, -0.6315,  0.9139,  0.7993, -0.9779,\n",
       "          0.6786,  0.8419,  0.2755, -0.3668, -0.1409,  0.9088, -0.3033,  0.3389,\n",
       "         -0.2061,  0.2883,  0.6131, -0.5824,  0.4671,  0.2862,  0.0357,  0.3380,\n",
       "         -0.4704, -0.8025,  0.1226, -0.0692, -0.2963, -0.8950, -0.0128, -0.3990,\n",
       "          0.0956,  0.2303,  0.0289, -0.4016,  0.1295, -0.5899, -0.0604, -0.3644,\n",
       "         -0.5683, -0.6072,  0.1960, -0.0058,  0.7062, -0.9002,  0.8535, -0.1984,\n",
       "         -0.4168,  0.9835, -0.4198, -0.7018,  0.1147,  0.2929,  0.4046,  0.9828,\n",
       "          0.3571, -0.9467,  0.2447,  0.0032, -0.3104, -0.3302,  0.7714, -0.1748,\n",
       "          0.6315,  0.2694,  0.9615, -0.9539, -0.3752, -0.6769, -0.8517,  0.8144,\n",
       "          0.8368,  0.1071, -0.2773,  0.1174,  0.7535,  0.1881, -0.5815,  0.1154,\n",
       "          0.2860, -0.2838,  0.6508, -0.3938,  0.3085,  0.3037,  0.1641,  0.3347,\n",
       "         -0.3499,  0.1851, -0.1806,  0.3030, -0.1458,  0.4082, -0.8229,  0.0302,\n",
       "          0.9684,  0.0667, -0.3508,  0.7129, -0.2124,  0.0821,  0.1991,  0.2246,\n",
       "         -0.2803, -0.2820, -0.2331, -0.4589, -0.9632,  0.3244,  0.2145, -0.1915,\n",
       "          0.8968, -0.2266,  0.2631, -0.2552, -0.2619,  0.1797,  0.0335, -0.7683,\n",
       "          0.9220, -0.3161, -0.4058,  0.6036,  0.7134, -0.2569, -0.2773,  0.2480,\n",
       "         -0.8766, -0.2656, -0.8519,  0.8501, -0.2626,  0.1594,  0.1835, -0.0579,\n",
       "          0.9583,  0.2908,  0.4125, -0.1950,  0.1511,  0.1448, -0.4434, -0.0425,\n",
       "         -0.3061,  0.7579, -0.1116,  0.3015, -0.8641, -0.7368,  0.0564, -0.3752,\n",
       "         -0.9268,  0.2653,  0.3690,  0.3397,  0.1615,  0.0463, -0.6323, -0.5730,\n",
       "         -0.1308, -0.8043,  0.6291, -0.2351,  0.1837, -0.1947, -0.2472, -0.7953,\n",
       "          0.7959,  0.1252,  0.2056, -0.2510, -0.3231,  0.1117, -0.2875,  0.3878,\n",
       "         -0.2150,  0.9871, -0.1589, -0.5462,  0.5207,  0.4598, -0.2556,  0.2950,\n",
       "         -0.3593,  0.2654,  0.7688,  0.5886, -0.2339, -0.2073,  0.3796, -0.3358,\n",
       "         -0.7645,  0.6770,  0.0131,  0.1966, -0.2259,  0.3514,  0.8593, -0.3256,\n",
       "         -0.1373, -0.3823, -0.3014, -0.1312, -0.1547,  0.9143,  0.3615, -0.0912,\n",
       "         -0.9633,  0.5178, -0.7469,  0.2733,  0.8361, -0.5289,  0.3136,  0.0315,\n",
       "         -0.1862,  0.2042, -0.1701, -0.0777,  0.1660,  0.1456,  0.9055, -0.2587,\n",
       "         -0.9246, -0.2548,  0.2523, -0.8363, -0.0559, -0.3265, -0.3341,  0.0063,\n",
       "          0.0408,  0.5735,  0.1051, -0.9054, -0.3130,  0.2282,  0.9161,  0.1414,\n",
       "          0.3357, -0.9168, -0.3919, -0.3784,  0.6003, -0.7013,  0.9445, -0.8395,\n",
       "         -0.0135,  0.9789,  0.3162, -0.5505,  0.2241, -0.3181,  0.2108,  0.2502,\n",
       "          0.3057, -0.7358, -0.2771, -0.2349,  0.3776, -0.2587, -0.0015,  0.6190,\n",
       "          0.2939,  0.2314, -0.1229, -0.3288,  0.1673,  0.5402, -0.2161, -0.2917,\n",
       "          0.2145, -0.2247, -0.7893, -0.2965, -0.2920, -0.2426,  0.1971, -0.9826,\n",
       "         -0.0617, -0.8092, -0.1477,  0.6744,  0.1837,  0.0328, -0.7805,  0.7064,\n",
       "          0.7379,  0.6279, -0.1511,  0.3817, -0.7610,  0.2257, -0.1732,  0.1196,\n",
       "          0.2288,  0.3585, -0.2010,  0.9922,  0.0649, -0.2619, -0.5335,  0.2773,\n",
       "         -0.1569,  0.6409, -0.5545, -0.9433,  0.1835, -0.5349, -0.5436,  0.1918,\n",
       "          0.1097, -0.0447,  0.2517,  0.7305,  0.2951,  0.2438,  0.0370, -0.2595,\n",
       "         -0.2227,  0.0907, -0.4845,  0.9362, -0.4015,  0.5792,  0.1621, -0.0251,\n",
       "          0.8507,  0.2759,  0.4797,  0.0798,  0.9621,  0.3414, -0.7577, -0.1839,\n",
       "         -0.7523, -0.3961, -0.7432,  0.2095,  0.1668,  0.7623, -0.2460,  0.8894,\n",
       "          0.6593,  0.2014,  0.2192,  0.6830,  0.2681, -0.8835, -0.9033, -0.9536,\n",
       "          0.0700, -0.2164, -0.3381,  0.1087,  0.2717,  0.1260,  0.1780, -0.8812,\n",
       "          0.8230,  0.2595, -0.7577,  0.9377, -0.1823,  0.2714,  0.1814, -0.9396,\n",
       "         -0.6249, -0.3092, -0.2146,  0.3007,  0.3970,  0.5871,  0.2873, -0.2533,\n",
       "         -0.2466,  0.5564,  0.4172, -0.9454,  0.2283,  0.6343, -0.6606,  0.8622,\n",
       "         -0.5868, -0.1367,  0.7186,  0.1075,  0.7842,  0.3043,  0.4852,  0.1849,\n",
       "          0.6055,  0.7989,  0.4348,  0.9461,  0.6588,  0.4474,  0.2761,  0.2627,\n",
       "          0.0089, -0.7053,  0.1058,  0.1725,  0.1867,  0.2713, -0.3031, -0.7423,\n",
       "          0.1006, -0.1925,  0.0981, -0.2417, -0.2267, -0.2410, -0.2470, -0.2342,\n",
       "         -0.1062, -0.3289,  0.0340,  0.8573, -0.1460, -0.2169, -0.2390, -0.1443,\n",
       "          0.7808, -0.7178,  0.3937, -0.0971,  0.7847, -0.2851,  0.2481, -0.1773,\n",
       "         -0.5796, -0.3111, -0.1373, -0.4485,  0.3852, -0.1636, -0.2432, -0.2380,\n",
       "          0.4613,  0.1320,  0.2598,  0.7067,  0.7142, -0.1058, -0.2413,  0.1026,\n",
       "         -0.2590, -0.8996,  0.2623, -0.0162, -0.5812,  0.5525, -0.2041,  0.3688,\n",
       "         -0.6902, -0.1047,  0.2439, -0.2807, -0.3113,  0.0382, -0.3474,  0.3175,\n",
       "         -0.5406,  0.7254, -0.3386,  0.7426, -0.3941,  0.0959, -0.3083,  0.4517]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dc4d57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu1",
   "language": "python",
   "name": "gpu1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
